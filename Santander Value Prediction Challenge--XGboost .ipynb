{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from mlxtend.preprocessing import minmax_scaling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop([\"ID\", \"target\"], axis=1)\n",
    "y_train = train_df[\"target\"]  # take log to train target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>48df886f9</th>\n",
       "      <th>0deb4b6a8</th>\n",
       "      <th>34b15f335</th>\n",
       "      <th>a8cb14b00</th>\n",
       "      <th>2f0771a37</th>\n",
       "      <th>30347e683</th>\n",
       "      <th>d08d1fbe3</th>\n",
       "      <th>6ee66e115</th>\n",
       "      <th>20aa07010</th>\n",
       "      <th>dc5a8f1d8</th>\n",
       "      <th>...</th>\n",
       "      <th>3ecc09859</th>\n",
       "      <th>9281abeea</th>\n",
       "      <th>8675bec0b</th>\n",
       "      <th>3a13ed79a</th>\n",
       "      <th>f677d4d13</th>\n",
       "      <th>71b203550</th>\n",
       "      <th>137efaa80</th>\n",
       "      <th>fb36b89d9</th>\n",
       "      <th>7e293fbaf</th>\n",
       "      <th>9fc776466</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2200000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4991 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   48df886f9  0deb4b6a8  34b15f335  a8cb14b00  2f0771a37  30347e683  \\\n",
       "0        0.0          0        0.0          0          0          0   \n",
       "1        0.0          0        0.0          0          0          0   \n",
       "2        0.0          0        0.0          0          0          0   \n",
       "3        0.0          0        0.0          0          0          0   \n",
       "4        0.0          0        0.0          0          0          0   \n",
       "\n",
       "   d08d1fbe3  6ee66e115  20aa07010  dc5a8f1d8    ...      3ecc09859  \\\n",
       "0          0          0        0.0        0.0    ...            0.0   \n",
       "1          0          0  2200000.0        0.0    ...            0.0   \n",
       "2          0          0        0.0        0.0    ...            0.0   \n",
       "3          0          0        0.0        0.0    ...            0.0   \n",
       "4          0          0  2000000.0        0.0    ...            0.0   \n",
       "\n",
       "   9281abeea  8675bec0b  3a13ed79a  f677d4d13  71b203550  137efaa80  \\\n",
       "0        0.0        0.0          0          0          0          0   \n",
       "1        0.0        0.0          0          0          0          0   \n",
       "2        0.0        0.0          0          0          0          0   \n",
       "3        0.0        0.0          0          0          0          0   \n",
       "4        0.0        0.0          0          0          0          0   \n",
       "\n",
       "   fb36b89d9  7e293fbaf  9fc776466  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  \n",
       "\n",
       "[5 rows x 4991 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed `256` Constant Columns\n",
      "\n",
      "['d5308d8bc', 'c330f1a67', 'eeac16933', '7df8788e8', '5b91580ee', '6f29fbbc7', '46dafc868', 'ae41a98b6', 'f416800e9', '6d07828ca', '7ac332a1d', '70ee7950a', '833b35a7c', '2f9969eab', '8b1372217', '68322788b', '2288ac1a6', 'dc7f76962', '467044c26', '39ebfbfd9', '9a5ff8c23', 'f6fac27c8', '664e2800e', 'ae28689a2', 'd87dcac58', '4065efbb6', 'f944d9d43', 'c2c4491d5', 'a4346e2e2', '1af366d4f', 'cfff5b7c8', 'da215e99e', '5acd26139', '9be9c6cef', '1210d0271', '21b0a54cb', 'da35e792b', '754c502dd', '0b346adbd', '0f196b049', 'b603ed95d', '2a50e001c', '1e81432e7', '10350ea43', '3c7c7e24c', '7585fce2a', '64d036163', 'f25d9935c', 'd98484125', '95c85e227', '9a5273600', '746cdb817', '6377a6293', '7d944fb0c', '87eb21c50', '5ea313a8c', '0987a65a1', '2fb7c2443', 'f5dde409b', '1ae50d4c3', '2b21cd7d8', '0db8a9272', '804d8b55b', '76f135fa6', '7d7182143', 'f88e61ae6', '378ed28e0', 'ca4ba131e', '1352ddae5', '2b601ad67', '6e42ff7c7', '22196a84c', '0e410eb3d', '992e6d1d3', '90a742107', '08b9ec4ae', 'd95203ded', '58ad51def', '9f69ae59f', '863de8a31', 'be10df47c', 'f006d9618', 'a7e39d23d', '5ed0abe85', '6c578fe94', '7fa4fcee9', '5e0571f07', 'fd5659511', 'e06b9f40f', 'c506599c8', '99de8c2dc', 'b05f4b229', '5e0834175', 'eb1cc0d9c', 'b281a62b9', '00fcf67e4', 'e37b65992', '2308e2b29', 'c342e8709', '708471ebf', 'f614aac15', '15ecf7b68', '3bfe540f1', '7a0d98f3c', 'e642315a5', 'c16d456a7', '0c9b5bcfa', 'b778ab129', '2ace87cdd', '697a566f0', '97b1f84fc', '34eff114b', '5281333d7', 'c89f3ba7e', 'cd6d3c7e6', 'fc7c8f2e8', 'abbbf9f82', '24a233e8f', '8e26b560e', 'a28ac1049', '504502ce1', 'd9a8615f3', '4efd6d283', '34cc56e83', '93e98252a', '2b6cef19e', 'c7f70a49b', '0d29ab7eb', 'e4a0d39b7', 'a4d1a8409', 'bc694fc8f', '3a36fc3a2', '4ffba44d3', '9bfdec4bc', '66a866d2f', 'f941e9df7', 'e7af4dbf3', 'dc9a54a3e', '748168a04', 'bba8ce4bb', 'ff6f62aa4', 'b06fe66ba', 'ae87ebc42', 'f26589e57', '963bb53b1', 'a531a4bf0', '9fc79985d', '9350d55c1', 'de06e884c', 'fc10bdf18', 'e0907e883', 'c586d79a1', 'e15e1513d', 'a06067897', '643e42fcb', '217cd3838', '047ebc242', '9b6ce40cf', '3b2c972b3', '17a7bf25a', 'c9028d46b', '9e0473c91', '6b041d374', '783c50218', '19122191d', 'ce573744f', '1c4ea481e', 'fbd6e0a0b', '69831c049', 'b87e3036b', '54ba515ee', 'a09ba0b15', '90f77ec55', 'fb02ef0ea', '3b0cccd29', 'fe9ed417c', '589e8bd6f', '17b5a03fd', '80e16b49a', 'a3d5c2c2a', '1bd3a4e92', '611d81daa', '3d7780b1c', '113fd0206', '5e5894826', 'cb36204f9', 'bc4e3d600', 'c66e2deb0', 'c25851298', 'a7f6de992', '3f93a3272', 'c1b95c2ec', '6bda21fee', '4a64e56e7', '943743753', '20854f8bf', 'ac2e428a9', '5ee7de0be', '316423a21', '2e52b0c6a', '8bdf6bc7e', '8f523faf2', '4758340d5', '8411096ec', '9678b95b7', 'a185e35cc', 'fa980a778', 'c8d90f7d7', '080540c81', '32591c8b4', '5779da33c', 'bb425b41e', '01599af81', '1654ab770', 'd334a588e', 'b4353599c', '51b53eaec', '2cc0fbc52', '45ffef194', 'c15ac04ee', '5b055c8ea', 'd0466eb58', 'a80633823', 'a117a5409', '7ddac276f', '8c32df8b3', 'e5649663e', '6c16efbb8', '9118fd5ca', 'ca8d565f1', '16a5bb8d2', 'fd6347461', 'f5179fb9c', '97428b646', 'f684b0a96', 'e4b2caa9f', '2c2d9f267', '96eb14eaf', 'cb2cb460c', '86f843927', 'ecd16fc60', '801c6dc8e', 'f859a25b8', 'ae846f332', '2252c7403', 'fb9e07326', 'd196ca1fd', 'a8e562e8e', 'eb6bb7ce1', '5beff147e', '52b347cdc', '4600aadcf', '6fa0b9dab', '43d70cc4d', '408021ef8', 'e29d22b59']\n",
      "Train set size: (4459, 4735)\n"
     ]
    }
   ],
   "source": [
    "colsToRemove = []\n",
    "for col in X_train.columns:\n",
    "    if X_train[col].std() == 0: \n",
    "        colsToRemove.append(col)\n",
    "X_train.drop(colsToRemove, axis=1, inplace=True)\n",
    "\n",
    "# remove constant columns in the test set\n",
    "#X_test.drop(colsToRemove, axis=1, inplace=True) \n",
    "\n",
    "print(\"Removed `{}` Constant Columns\\n\".format(len(colsToRemove)))\n",
    "print(colsToRemove)\n",
    "\n",
    "print(\"Train set size: {}\".format(X_train.shape))\n",
    "# print(\"Test set size: {}\".format(X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize dataset so that every value is in the same range "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "X_train=StandardScaler().fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pdhe/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split training dataset and test dataset\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, \n",
    "                                                    test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-rmse:8.94374e+06\n",
      "Will train until validation_0-rmse hasn't improved in 100 rounds.\n",
      "[1]\tvalidation_0-rmse:8.55215e+06\n",
      "[2]\tvalidation_0-rmse:8.24316e+06\n",
      "[3]\tvalidation_0-rmse:7.94893e+06\n",
      "[4]\tvalidation_0-rmse:7.70254e+06\n",
      "[5]\tvalidation_0-rmse:7.50576e+06\n",
      "[6]\tvalidation_0-rmse:7.33335e+06\n",
      "[7]\tvalidation_0-rmse:7.20213e+06\n",
      "[8]\tvalidation_0-rmse:7.09016e+06\n",
      "[9]\tvalidation_0-rmse:6.99392e+06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.7, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=10, min_child_weight=1, missing=None, n_estimators=10,\n",
       "       n_jobs=1, nthread=-1, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=1440,\n",
       "       silent=True, subsample=0.85)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Xgboost regressor\n",
    "import xgboost as xgb\n",
    "xlf = xgb.XGBRegressor(max_depth=10, \n",
    "                        learning_rate=0.1, \n",
    "                        n_estimators=10, \n",
    "                        silent=True, \n",
    "                        objective='reg:linear', \n",
    "                        nthread=-1, \n",
    "                        gamma=0,\n",
    "                        min_child_weight=1, \n",
    "                        max_delta_step=0, \n",
    "                        subsample=0.85, \n",
    "                        colsample_bytree=0.7, \n",
    "                        colsample_bylevel=1, \n",
    "                        reg_alpha=0, \n",
    "                        reg_lambda=1, \n",
    "                        scale_pos_weight=1, \n",
    "                        seed=1440, \n",
    "                        missing=None)\n",
    "\n",
    "xlf.fit(X_train, y_train, eval_metric='rmse', verbose = True, eval_set = [(X_test, y_test)],early_stopping_rounds=100)\n",
    "\n",
    "# 计算 auc 分数、预测\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xlf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3055092.75 ,   2623424.   ,   4427569.5  ,   3083113.5  ,\n",
       "         3083113.5  ,   5600924.5  ,   5905122.5  ,   4354622.5  ,\n",
       "         3083113.5  ,   2776347.75 ,   7853575.   ,   3083113.5  ,\n",
       "         5962904.   ,   3091903.75 ,   2644754.   ,   2898670.75 ,\n",
       "         2870650.   ,   3627464.   ,   5723733.5  ,   4377585.5  ,\n",
       "         2892089.25 ,   3083113.5  ,   3083113.5  ,   2898670.75 ,\n",
       "         3083113.5  ,   8488786.   ,   3786191.   ,   2777491.   ,\n",
       "         2499008.   ,   2593048.5  ,   4122797.5  ,   8514862.   ,\n",
       "         3083113.5  ,   3083113.5  ,   2859514.   ,   2777491.   ,\n",
       "         2154689.   ,   6628306.   ,   2350074.5  ,   7370660.   ,\n",
       "         4243743.   ,   4122797.5  ,   2623314.75 ,   3314191.25 ,\n",
       "         4263634.5  ,   2644754.   ,   4580838.   ,   4923251.   ,\n",
       "         1870289.75 ,   5052579.   ,   5065876.5  ,   2870650.   ,\n",
       "         3432977.75 ,   3564403.5  ,   3083113.5  ,   2423862.25 ,\n",
       "        13034576.   ,   2182443.   ,   1878352.25 ,   5969404.   ,\n",
       "         2898670.75 ,   2644754.   ,   3083113.5  ,   3083113.5  ,\n",
       "         3176498.25 ,   3083113.5  ,   2891916.   ,   2691959.5  ,\n",
       "         1755026.125,   7370302.5  ,   3083113.5  ,   2223918.5  ,\n",
       "         2846721.   ,   3083113.5  ,   2499008.   ,   3083113.5  ,\n",
       "         3304367.25 ,   3006312.25 ,   6090014.   ,   3314191.25 ,\n",
       "         2198643.75 ,   3055092.75 ,   3434451.25 ,   4804473.   ,\n",
       "         2679625.75 ,   3083113.5  ,   2971140.5  ,   2456764.75 ,\n",
       "         2707646.5  ,   3083113.5  ,   4667977.5  ,   2364787.   ,\n",
       "         2709808.75 ,   2435036.25 ,   2851645.5  ,   2898670.75 ,\n",
       "         2870650.   ,   2681788.   ,   3697369.5  ,   3482572.25 ,\n",
       "         2651335.25 ,   8161979.5  ,   2828335.   ,   2593048.5  ,\n",
       "         2777491.   ,   2059348.5  ,   3083113.5  ,   3606991.25 ,\n",
       "         2655523.5  ,   3101727.75 ,   2903041.75 ,   2172797.   ,\n",
       "         3083113.5  ,   2898670.75 ,   4804473.   ,   3083113.5  ,\n",
       "         3315513.5  ,   2820631.   ,   2496936.   ,   2898670.75 ,\n",
       "         3083113.5  ,   9642816.   ,   2502122.25 ,   2892089.25 ,\n",
       "         2957144.   ,   2870650.   ,   3005073.75 ,   2892089.25 ,\n",
       "         2644754.   ,   3083113.5  ,   5336897.5  ,   5216932.   ,\n",
       "         3083113.5  ,   2806487.25 ,   3083113.5  ,   4272563.5  ,\n",
       "         3333921.   ,   3083113.5  ,   4273173.5  ,   2678691.75 ,\n",
       "         2864068.5  ,   5430637.5  ,   3947973.5  ,   3083113.5  ,\n",
       "         3533061.   ,   3083113.5  ,   3178397.75 ,   3162980.25 ,\n",
       "         3627464.   ,   2735400.5  ,   4353106.5  ,   2234584.25 ,\n",
       "         2545041.75 ,   1996445.625,   2645112.5  ,   3083113.5  ,\n",
       "         2707646.5  ,   3139251.25 ,   3083113.5  ,   2193385.75 ,\n",
       "         3083113.5  ,   4477044.5  ,   2644754.   ,   2898670.75 ,\n",
       "         3148510.   ,   2225932.5  ,   2866007.75 ,   6453643.5  ,\n",
       "         3083113.5  ,   2658127.   ,   2840695.5  ,   3314191.25 ,\n",
       "         4813440.5  ,   3083113.5  ,   4579784.   ,   3132972.   ,\n",
       "         3083113.5  ,   3443021.   ,   3083113.5  ,   1893737.25 ,\n",
       "         2462184.   ,   2193385.75 ,   2957144.   ,   3083113.5  ,\n",
       "         3443786.5  ,   8950800.   ,   2593048.5  ,   3203009.25 ,\n",
       "         3083113.5  ,   3083113.5  ,   2898670.75 ,   2835778.25 ,\n",
       "         2681788.   ,   2436551.25 ,   7420410.   ,   3594311.5  ,\n",
       "         3083113.5  ,   3085322.25 ,   3394570.25 ,   2488065.   ,\n",
       "         3083113.5  ,   3083113.5  ,   2923687.25 ,   2846721.   ,\n",
       "         2681788.   ,   3083113.5  ,   5642510.5  ,   3098580.75 ,\n",
       "         3432011.5  ,   3690750.25 ,   4771883.   ,   3689886.25 ,\n",
       "         3055092.75 ,   3083113.5  ,   3119924.5  ,   2219547.5  ,\n",
       "         3123167.   ,   2898670.75 ,   2738099.   ,   2898670.75 ,\n",
       "         3036814.5  ,   2466336.5  ,   4444430.5  ,   3083113.5  ,\n",
       "         6633190.5  ,   3083113.5  ,   2720953.75 ,   4047713.5  ,\n",
       "         3083113.5  ,   3083113.5  ,   3083113.5  ,   3176139.25 ,\n",
       "         2331234.25 ,   3083113.5  ,   4630886.   ,   2434099.   ,\n",
       "         3674171.75 ,   3083113.5  ,   2777491.   ,   3083113.5  ,\n",
       "         5608895.5  ,   4813014.   ,   4031206.25 ,   2835778.25 ,\n",
       "         3397607.   ,   4423457.   ,   4169109.   ,   3083113.5  ,\n",
       "         1684497.   ,   5365956.5  ,   4385712.   ,   3083113.5  ,\n",
       "         2680123.75 ,   2881313.   ,   3083113.5  ,   2692730.75 ,\n",
       "         2340040.75 ,   2720751.5  ,   2898670.75 ,   2957144.   ,\n",
       "         3083113.5  ,   2593048.5  ,   2847711.5  ,   2490763.75 ,\n",
       "         3083113.5  ,   3083113.5  ,   2729484.5  ,   2681298.25 ,\n",
       "         3394058.   ,   2735400.5  ,   2846721.   ,   2390550.   ,\n",
       "         2777491.   ,  10280698.   ,   3083113.5  ,   2307983.75 ,\n",
       "         3466335.75 ,   3083113.5  ,   4870370.5  ,   6018181.5  ,\n",
       "         3083113.5  ,   6929873.5  ,   2957144.   ,   4146449.75 ,\n",
       "         6059124.5  ,   3581168.25 ,   2957144.   ,   4061116.5  ,\n",
       "         4498622.5  ,   2898670.75 ,   3083113.5  ,   2681788.   ,\n",
       "         3083113.5  ,   3083113.5  ,  12429512.   ,   3162980.25 ,\n",
       "         3083113.5  ,   3177453.5  ,   2846721.   ,   3083113.5  ,\n",
       "         3005073.75 ,   3581634.   ,   2898670.75 ,   3083113.5  ,\n",
       "         5194469.5  ,   2644754.   ,   3868590.25 ,   2518784.25 ,\n",
       "         8042378.   ,   3083113.5  ,   2530155.75 ,   3083113.5  ,\n",
       "         2992877.75 ,   3500046.   ,  10479046.   ,   1991418.625,\n",
       "         3083113.5  ,   3937526.   ,   5526800.5  ,   4122797.5  ,\n",
       "         2079033.   ,   2898670.75 ,   6925830.5  ,   4322725.5  ,\n",
       "         3083113.5  ,   2929123.25 ,   3083113.5  ,   8739502.   ,\n",
       "         2835778.25 ,   3092924.25 ,   5332525.5  ,   2892089.25 ,\n",
       "         3083113.5  ,   2898670.75 ,   2835778.25 ,   2709454.75 ,\n",
       "         4011781.   ,   2992767.   ,   3956400.75 ,   2631258.25 ,\n",
       "         3083113.5  ,   3874182.75 ,   2864385.   ,   2957144.   ,\n",
       "         2518784.25 ,   6084285.   ,   2166040.   ,  21163692.   ,\n",
       "         7946655.   ,   2182443.   ,   3083113.5  ,   6791575.5  ,\n",
       "         2953564.5  ,   7406661.5  ,   3083113.5  ,   3086107.75 ,\n",
       "         3083113.5  ,   2655696.75 ,   2764282.25 ,   3760589.25 ,\n",
       "         3083113.5  ,   2852226.5  ,   2892089.25 ,   1401397.125,\n",
       "        11643892.   ,   3083113.5  ,  10735396.   ,   2870650.   ,\n",
       "         6781755.5  ,   2929123.25 ,   4427441.5  ,   3083113.5  ,\n",
       "         3083113.5  ,   4713057.   ,   3083113.5  ,  12076470.   ,\n",
       "         2238754.25 ,   2976771.5  ,   2777491.   ,   2642711.75 ,\n",
       "         8848238.   ,   3083113.5  ,   3508123.   ,   2102739.   ,\n",
       "         3552326.   ,   3083113.5  ,   3428916.   ,   2541098.5  ,\n",
       "         1658763.   ,   5609180.5  ,   3083113.5  ,   4546867.   ,\n",
       "         3083113.5  ,   3083113.5  ,   4366686.5  ,   3083113.5  ,\n",
       "         2898670.75 ,   2954808.5  ,  12370482.   ,   3119924.5  ,\n",
       "         4522593.   ,   1991418.625,   3083113.5  ,   3057872.5  ,\n",
       "         4598006.5  ,   1856550.375,   3162861.   ,   3670843.75 ,\n",
       "         1991418.625,   3893645.5  ,   2499875.5  ,   5503066.5  ,\n",
       "         4656763.5  ,  10325726.   ,  19230356.   ,   2892089.25 ,\n",
       "         3083113.5  ,   2898670.75 ,   4184354.75 ,   2651521.75 ,\n",
       "         5327258.5  ,   5272969.5  ,   2702501.75 ,   2460044.5  ,\n",
       "         3083113.5  ,   7363573.   ,   9721438.   ,   2777491.   ,\n",
       "         1637789.625,   1991418.625,  10285754.   ,   2749297.25 ,\n",
       "         6677335.   ,   4544073.   ,   2835778.25 ,   3083113.5  ,\n",
       "         3083113.5  ,   2870650.   ,   2593360.   ,   3083113.5  ,\n",
       "         2488065.   ,  16574184.   ,   3083113.5  ,   3083113.5  ,\n",
       "         2345713.   ,   5340880.   ,  10141348.   ,   3119924.5  ,\n",
       "         2754146.5  ,   3150377.   ,   3083113.5  ,   3083113.5  ,\n",
       "         2544203.   ,   3083113.5  ,   7346867.5  ,   3083113.5  ,\n",
       "         2544376.25 ,   2735400.5  ,   3083113.5  ,   2574726.   ,\n",
       "         1651638.25 ,   2835778.25 ,   3083113.5  ,   8103068.5  ,\n",
       "         3279750.75 ,   2892089.25 ,   2682850.5  ,   3513649.25 ,\n",
       "         3083113.5  ,   2898670.75 ,   2835778.25 ,   4660337.5  ,\n",
       "         3139317.   ,   4042176.25 ,   5249188.   ,   3083113.5  ,\n",
       "         3083113.5  ,   2979773.75 ,   3057032.   ,   3083113.5  ,\n",
       "         3934142.5  ,   3083113.5  ,   2599385.75 ,   7136280.   ,\n",
       "         3083113.5  ,   4137592.5  ,   3083113.5  ,   2593048.5  ,\n",
       "         2561005.5  ,   2818700.25 ,   2835778.25 ,  11048966.   ,\n",
       "         3083113.5  ,   5839937.5  ,   3996943.25 ,   3083113.5  ,\n",
       "         4804473.   ,   3055092.75 ,   2898670.75 ,   5899488.   ,\n",
       "         2544203.   ,   3083113.5  ,   2537515.   ,   3083113.5  ,\n",
       "         2387684.25 ,   2835778.25 ,   2939095.   ,   2957144.   ,\n",
       "         3083113.5  ,   3055092.75 ,   3085693.75 ,   3304367.25 ,\n",
       "         2109320.5  ,   6344846.5  ,   2109320.5  ,   3314191.25 ,\n",
       "         3581195.25 ,   3083113.5  ,   4566021.5  ,   5529241.5  ,\n",
       "         2681089.   ,   2902858.75 ,   3083113.5  ,   4044797.   ,\n",
       "         4170587.   ,   9944160.   ,   2356656.   ,   3083113.5  ,\n",
       "         5962711.   ,   3453744.75 ,   4498184.   ,   7459080.5  ,\n",
       "         4559034.   ,   2644754.   ,  21009686.   ,   2846721.   ,\n",
       "         3083113.5  ,   2898670.75 ,   2681788.   ,   3598708.   ,\n",
       "         3083113.5  ,   2976771.5  ,  14233614.   ,   2404186.25 ,\n",
       "         3142425.   ,   3083113.5  ,   2846721.   ,   7108895.5  ,\n",
       "         2460311.   ,   2735400.5  ,   2023341.   ,   2978537.25 ,\n",
       "         9108114.   ,   2660707.   ,   2965471.5  ,   1755026.125,\n",
       "         3379713.   ,   3653594.   ,   3083113.5  ,   2783966.75 ,\n",
       "         4917854.   ,   2777491.   ,   5715638.5  ,   2957144.   ,\n",
       "         4716531.   ,   1991418.625,   3083113.5  ,   6828935.5  ,\n",
       "         3083113.5  ,   2898670.75 ,   6332268.   ,   2835778.25 ,\n",
       "         2766119.75 ,   4152269.5  ,   6407850.5  ,   2599232.75 ,\n",
       "         2892089.25 ,   3083113.5  ,   2297041.   ,   2807757.5  ,\n",
       "         5179861.5  ,   2297041.   ,   3314191.25 ,   5390559.   ,\n",
       "         3083113.5  ,   3083113.5  ,   6332268.   ,   3627267.25 ,\n",
       "         4306393.   ,  20801526.   ,   2835778.25 ,  21163692.   ,\n",
       "         2029348.125,   3812438.75 ,   3397607.   ,   3083113.5  ,\n",
       "         5957033.5  ,   3083113.5  ,   2429778.25 ,   2846721.   ,\n",
       "         2835778.25 ,   3083113.5  ,   2909936.25 ,   3479833.   ,\n",
       "         2928727.   ,  19474550.   ,   7402699.   ,   3083113.5  ,\n",
       "         1991418.625,   6490393.5  ,   5649464.   ,   2644754.   ,\n",
       "         2835778.25 ,   3083113.5  ,   3670843.75 ,   2350074.5  ,\n",
       "         2835778.25 ,   3083113.5  ,  10635128.   ,   3083113.5  ,\n",
       "         5700856.5  ,   3083113.5  ,   2879104.25 ,   3846763.25 ,\n",
       "         4751209.   ,   4907696.5  ,   2651335.25 ,   5399239.5  ,\n",
       "         4939967.   ,   5727343.5  ,   3083113.5  ,   3709730.   ,\n",
       "         2898670.75 ,   8250944.5  ,   3056796.   ,   3084235.75 ,\n",
       "         3083113.5  ,   5379386.5  ,   2475237.25 ,   3083113.5  ,\n",
       "         3083113.5  ,   1991418.625,   3083113.5  ,  20275880.   ,\n",
       "         2902009.75 ,   3083113.5  ,   2440468.25 ,   3384234.   ,\n",
       "         2616670.25 ,   5905122.5  ,   3083113.5  ,   2818700.25 ,\n",
       "         3083113.5  ,   2193385.75 ,   3083113.5  ,   2657360.75 ,\n",
       "         4194103.5  ,   6543876.   ,   3083113.5  ,   3083113.5  ,\n",
       "         3734989.75 ,   2822257.5  ,   5905122.5  ,   3083113.5  ,\n",
       "         3670843.75 ,   1510058.   ,   3083113.5  ,   3083113.5  ,\n",
       "         3285939.25 ,   2280865.75 ,   6931540.5  ,   3135180.75 ,\n",
       "         3083113.5  ,   6315932.5  ,   4122797.5  ,   3801395.   ,\n",
       "         5561314.   ,   3083113.5  ,   3083113.5  ,   8115085.   ,\n",
       "         2525169.5  ,   3083113.5  ,   3963363.5  ,   2593048.5  ,\n",
       "         3433491.75 ,   2898670.75 ,   3083113.5  ,   3073811.   ,\n",
       "         2735400.5  ,   4528828.   ,   3083113.5  ,   3083113.5  ,\n",
       "         3041745.5  ,   1898043.75 ,   4453308.5  ,   2778764.   ,\n",
       "         2651521.75 ,  17992356.   ,   3956761.5  ,   2662278.25 ,\n",
       "         2846721.   ,   3515315.   ,   3314191.25 ,   4146988.25 ,\n",
       "         2738522.   ,   4018896.25 ,   5544381.5  ,   4113594.   ,\n",
       "         3083113.5  ,   3139251.25 ,   2898670.75 ,   5080599.5  ,\n",
       "         2818700.25 ,   6199554.   ,   3355997.25 ,   2835778.25 ,\n",
       "         4670441.   ,   3893410.   ,   3937526.   ,   2345713.   ,\n",
       "         2651335.25 ,   2957144.   ,   2530155.75 ,   2735400.5  ,\n",
       "         3083113.5  ,   6679125.   ,   2729484.5  ,   2614838.5  ,\n",
       "         2846721.   ,   3083113.5  ,   3397607.   ,   2828790.   ,\n",
       "         4122797.5  ,   2692730.75 ,   2681788.   ,   5359223.5  ,\n",
       "         2846721.   ,   2846721.   ,   3718964.75 ,   4178935.5  ,\n",
       "         3631446.25 ,   4907423.5  ,   3083113.5  ,   4626338.5  ,\n",
       "         1984900.875,   3083113.5  ,   4232102.   ,   2957144.   ,\n",
       "         2766119.75 ,   2265740.75 ,   3083113.5  ,   4956570.   ,\n",
       "         3083113.5  ,   3162821.75 ,   3912197.75 ,   7085156.5  ,\n",
       "         3956400.75 ,   3083113.5  ,   6332268.   ,   2029348.125,\n",
       "         3848389.25 ,   2862148.5  ,   2957144.   ,   1481313.375,\n",
       "         3083113.5  ,   2575880.75 ,   2735400.5  ,   2845986.25 ,\n",
       "         2714124.25 ,   7269475.5  ,   3274724.25 ,   4802091.5  ,\n",
       "         2735400.5  ,   2774629.5  ,   2109320.5  ,   2929123.25 ,\n",
       "         5197846.   ,   4801259.5  ,   4092721.25 ,   3500046.   ,\n",
       "         2835778.25 ,  10254260.   ,   4313733.5  ,   3162980.25 ,\n",
       "         2957144.   ,   2707696.75 ,   2488065.   ,   2632938.5  ,\n",
       "         2835778.25 ,   2898670.75 ,   2735400.5  ,   7257808.5  ,\n",
       "         2835778.25 ,   5594522.   ,   3083113.5  ,   2665142.5  ,\n",
       "         2683106.75 ,   4096260.5  ,   3129717.75 ,   3083113.5  ,\n",
       "         2307188.5  ,   3304367.25 ,   3311409.75 ,   3083113.5  ,\n",
       "         3083113.5  ,   2957144.   ,   3083113.5  ,   2644754.   ,\n",
       "         2644754.   ,   2957144.   ,   2470987.25 ,   2265740.75 ,\n",
       "        10402536.   ,   3083113.5  ,   1967503.375,   5832085.   ,\n",
       "         2651521.75 ,   3083113.5  ,   3083113.5  ,   4041987.25 ,\n",
       "         2707646.5  ,   2846721.   ,   4153065.25 ,   2898670.75 ,\n",
       "         4758649.   ,   3083113.5  ,   2846721.   ,   3083113.5  ,\n",
       "         4804473.   ,   2704100.   ,   3690754.25 ,   3083113.5  ,\n",
       "         8911916.   ,   2207267.5  ,   5169760.   ,   3083113.5  ,\n",
       "         2289791.75 ,   3314191.25 ,   2927283.5  ,   3314191.25 ,\n",
       "         3984086.75 ,   3423454.5  ,  12777248.   ,   2544376.25 ,\n",
       "         4165534.5  ,   4719464.5  ,   4687802.   ,   6556294.5  ,\n",
       "         4891894.5  ,   2818700.25 ,   2593048.5  ,   2735400.5  ,\n",
       "         3083113.5  ,   4122797.5  ,   3956400.75 ,   5156431.5  ,\n",
       "         3083113.5  ,   7799299.5  ,   3083113.5  ,   7322085.   ,\n",
       "         2709808.75 ,   2835778.25 ,   2898670.75 ,   2238754.25 ,\n",
       "         2846721.   ,   3049893.75 ,   3114178.5  ,   2651521.75 ,\n",
       "         2404186.25 ,   3063134.75 ,   4411232.5  ,   3162980.25 ,\n",
       "         2835778.25 ,   3083113.5  ,   2957144.   ,   2737433.75 ,\n",
       "         3083113.5  ,   3083113.5  ,   2798542.5  ,   5224351.   ,\n",
       "         3266008.   ,   2770112.5  ,   2544376.25 ,   2711834.5  ,\n",
       "         4446767.5  ,   3317085.75 ,  13400498.   ,   7963895.   ,\n",
       "         3083113.5  ,   2681788.   ,   2815267.   ,   3083113.5  ], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score is 0.1374472731506553\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"R2 Score is {}\".format(metrics.r2_score(y_test,preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(preds,y_test):\n",
    "    diff=np.log(preds+1)-np.log(y_test+1)\n",
    "    square_diff=np.square(diff)\n",
    "    avg=np.mean(square_diff)\n",
    "    return('RMSLE',np.sqrt(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RMSLE', 1.7068602643683972)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSLE(preds,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### without EDA RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset = pd.read_csv('train.csv')\n",
    "testset = pd.read_csv('test.csv')\n",
    "\n",
    "X = dataset.iloc[:, 2:].values\n",
    "y = dataset.iloc[:, 1].values\n",
    "X_Test = testset.iloc[:,1:].values\n",
    "y = np.log(y)\n",
    "\n",
    "##get rid of features without variance\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "feature_selector = VarianceThreshold()\n",
    "X = feature_selector.fit_transform(X)\n",
    "X_Test = feature_selector.transform(X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=300,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "regressor = XGBRegressor(n_estimators=300)\n",
    "regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = regressor.predict(X_Test)\n",
    "results = np.exp(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['ID'] = testset['ID']\n",
    "submission['target'] = results\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
